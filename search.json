[{"categories":null,"content":"前言 OpenShift 4.X 版本要求安装在操作系统为 CoreOS 的机器上，因此 官方文档 给出了使用 PXE 或 IPXE 引导 CoreOS 系统的方法。我们可以参考其操作流程，将一台 CentOS 7.X 的机器改写为 CoreOS 系统，步骤如下：\n  从 镜像下载页 下载安装所需版本的 kernel、initramfs 和 rootfs 文件，并将 rootfs 和点火文件（*.ign）上传到自建的 HTTP 服务器上；\n  将 kernel 和 initramfs 文件拷贝到 CentOS 7.X 机器的 /boot 目录下；\n  根据需求修改 /boot/grub2 目录下的 grub.cfg 文件；\n  重启机器。\n  对于操作系统初学者（比如我）来说，很难想象仅依靠添加和修改文件就能改变一台计算机的操作系统。为了解其实现原理，我们将对 Linux 的启动流程进行讨论，并从中说明上述操作是如何影响操作系统的。\nLinux 启动流程 启动一台 Linux 机器的过程可以分为两个部分：Boot 和 Startup。其中，Boot 起始于计算机启动，在内核初始化完成且 systemd 进程开始加载后结束。紧接着， Startup 接管任务，使计算机达到一个用户可操作的状态。\nBoot 阶段 如上图所示，Boot 阶段又可以细分为三个部分：\n BIOS POST Boot Loader 内核初始化  BIOS POST 开机自检（Power On Self Test，POST）是 基本输入输出系统（Basic I/O System，BIOS）的一部分，也是启动 Linux 机器的第一个步骤。其工作对象是计算机硬件，因此对于任何操作系统都是相同的。POST 检查硬件的基本可操作性，若失败则 Boot 过程将会被终止。\nPOST 检查完毕后会发出一个 BIOS 中断调用 INT 13H，它将在任何可连接且可引导的磁盘上搜索含有有效引导记录的引导扇区（Boot Sector），通常是 主引导扇区。引导扇区中的主引导记录（Master Boot Record，MBR）将被加载到 RAM 中，然后控制权就会转移到其手中。\nBoot Loader 大多数 Linux 发行版使用三种 Boot Loader 程序：GRUB1、GRUB2 和 LILO，其中 GRUB2 是最新且使用最为广泛的。GRUB2 代表“GRand Unified Bootloader, version 2”，它能够定位操作系统内核并将其加载到内存中。GRUB2 还允许用户选择从几种不同的内核中引导计算机，如果更新的内核版本出现兼容性问题，我们就可以恢复到先前内核版本。\nGRUB1 的引导过程可以分为三个阶段：stage 1、stage 1.5 和 stage 2。虽然 GRUB2 中并没有 stage 的概念，但两者的工作方式基本相同。为了方便说明，我们在讨论 GRUB2 时将沿用 GRUB1 中 stage 的说法。\nstage 1 上文提到，BIOS 中断调用会定位主引导扇区，其结构如下图所示：\n主引导记录首部的引导代码便是 stage 1 文件 boot.img，它和 stage 1.5 文件 core.img 均位于 /boot/grub2/i386-pc 目录下：\n1 2 3  [root@bastion ~]# du -b /boot/grub2/i386-pc/*.img  512 /boot/grub2/i386-pc/boot.img 26664 /boot/grub2/i386-pc/core.img   它的作用是检查分区表是否正确，然后定位和加载 stage 1.5 文件。446 字节的 boot.img 放不下能够识别文件系统的代码，只能通过计算扇区的偏移量来寻找，因此 core.img 必须位于主引导记录和驱动器的第一个分区（partition）之间。第一个分区从扇区 63 开始，与位于扇区 0 的主引导记录之间有 62 个扇区（每个 512 字节），有足够的空间存储大小不足 30000 字节的 core.img 文件。当 core.img 文件加载到 RAM 后，控制权也随之转移。\nstage 1.5 相比于只能读取原始扇区的 LILO，GRUB1 和 GRUB2 均可识别文件系统，这依赖于 stage 1.5 文件中内置的文件系统驱动程序。如果你拥有一台仍然使用 GRUB1 引导的 CentOS 6.X 机器，那么便可以在 /boot/grub/ 目录下找到这些适配不同文件系统的 stage 1.5 文件：\n1 2 3 4 5 6 7 8 9 10 11  [root@centos6.5 ~]# du -b /boot/grub/* | grep stage1_5 13380 /boot/grub/e2fs_stage1_5 12620 /boot/grub/fat_stage1_5 11748 /boot/grub/ffs_stage1_5 11756 /boot/grub/iso9660_stage1_5 13268 /boot/grub/jfs_stage1_5 11956 /boot/grub/minix_stage1_5 14412 /boot/grub/reiserfs_stage1_5 12024 /boot/grub/ufs2_stage1_5 11364 /boot/grub/vstafs_stage1_5 13964 /boot/grub/xfs_stage1_5   GRUB2 中的 core.img 不仅整合了上述文件系统驱动，还新增了菜单处理等模块，这也是其优于 GRUB1 的地方。我们可以在 GNU GRUB Manual 2.06: Images 中找到对各种 GRUB 镜像文件的详细介绍。\n既然 core.img 文件可以识别文件系统，那么它就能够根据安装时确定的系统路径定位和加载 stage 2 文件。同样，当 stage 2 文件加载到 RAM 后，控制权也随之转移。\nstage 2 stage 2 文件并非是一个 .img 的镜像，而是一些运行时内核模块：\n1 2 3 4 5 6 7 8 9 10 11  [root@bastion ~]# ls /boot/grub2/i386-pc/ | grep .mod | head acpi.mod adler32.mod affs.mod afs.mod ahci.mod all_video.mod aout.mod appendedsig.mod appended_signature_test.mod archelp.mod   它们的任务是根据 grub.cfg 文件的配置定位和加载内核文件，然后将控制权转交给 Linux 内核。grub.cfg 文件存放在 /boot/grub2 目录下：\n1 2 3 4 5 6  [root@bastion ~]# head /boot/grub2/grub.cfg -n 5 # # DO NOT EDIT THIS FILE # # It is automatically generated by grub2-mkconfig using templates # from /etc/grub.d and settings from /etc/default/grub   通过该文件的注释我们可以知道，它实际上是由 grub2-mkconfig 命令使用 /etc/grub.d 目录下的一些模板文件并根据 /etc/default/grub 文件中的设置生成的：\n1 2  [root@bastion ~]# ls /etc/grub.d/ 00_header 00_tuned 01_users 10_linux 20_linux_xen 20_ppc_terminfo 30_os-prober 40_custom 41_custom README   40_custom 和 41_custom 文件常用于用户对 GRUB2 配置的修改，实际上我们对机器的操作也是从这里开始的。为了让 GRUB2 在机器启动时选择 CoreOS 系统内核而非默认的 CentOS，需要在原始 40_custom 文件末尾添加如下内容：\n1 2 3 4 5  menuentry 'coreos' { set root='hd0,msdos1' linux16 /rhcos-live-kernel-x86_64 coreos.inst=yes coreos.inst.install_dev=vda rd.neednet=1 console=tty0 console=ttyS0 coreos.live.rootfs_url=http://{{HTTP-Server-Path}}/rhcos-live-rootfs.x86_64.img coreos.inst.ignition_url=http://{{HTTP-Server-Path}}/master.ign ip=dhcp initrd16 /rhcos-live-initramfs.x86_64.img }   所示的 Menuentry 由三条 Shell 命令组成：\n set root='hd0,msdos1' linux16 /rhcos-live-kernel-x86_64 ... initrd16 /rhcos-live-initramfs.x86_64.img  第一条命令指定了 GRUB2 的根目录，也就是 /boot 所在分区在计算机硬件上的位置。既然我们已经将内核文件拷贝到了 /boot 目录下，那么能够识别文件系统的 GRUB2 便可以定位和加载它。本例中hd代表硬盘（hard drive），0代表第一块硬盘，mosdos代表分区格式，1 代表第一个分区。详细的硬件命名规范见 Naming Convention。\n第二条命令将从rhcos-live-kernel-x86_64（CoreOS 系统的内核文件）中以 16 位模式加载 Linux 内核映像，并通过coreos.live.rootfs_url和coreos.inst.ignition_url参数指定根文件系统（rootfs）的镜像文件和点火文件的下载链接。ip=dhcp代表该计算机网络将由 DHCP 服务器动态配置，也可以按ip={{HostIP}}::{{Gateway}}:{{Genmask}}:{{Hostname}}::none nameserver={{DNSServer}}的格式写入静态配置。\n第三条命令将从rhcos-live-initramfs.x86_64.img中加载 RAM Filesystem。GRUB2 读取的内核文件实际上只包含了内核的核心模块，缺少硬件驱动模块的它无法完成 rootfs 的挂载。然而这些硬件驱动模块位于 /lib/modules/$(uname -r)/kernel/ 目录下，必须在 rootfs 挂载完毕后才能被识别和加载。为了解决这一问题，initramfs（前身为 initrd）应运而生。它是一个包含了必要驱动模块的临时 rootfs，内核可以从中加载所需的驱动程序。待真正的 rootfs 挂载完毕后，它便会从内存中移除。\n除此之外我们还需要将 /etc/default/grub 文件中的 GRUB_DEFAULT=saved 修改为 GRUB_DEFAULT=“coreos”，使其与 40_custom 文件中的menuentry 'coreos'对应。最后使用命令grub2-mkconfig -o /boot/grub2/grub.cfg来重新生成一份 grub.cfg 文件，这样计算机重启后 GRUB2 就会根据我们的配置去加载 CoreOS 系统的内核了。\n至此我们已经明白了为什么“仅依靠添加和修改文件就能改变一台计算机的操作系统”，但计算机想要达到用户可操作状态还远不止于此。让我们再来看看内核被加载到内存后发生了什么。\n内核初始化 不同内核及其相关文件位于 /boot 目录中，均以 vmlinuz 开头：\n1 2 3 4  [root@bastion ~]# ls /boot/ | grep vmlinuz vmlinuz-0-rescue-20210623110808105647395700239158 vmlinuz-4.18.0-305.12.1.el8_4.x86_64 vmlinuz-4.18.0-305.3.1.el8.x86_64   内核通过压缩自身来节省存储空间，所以当选定的内核被加载到内存中后，它首先需要进行解压缩（extracting）。一旦解压完成，内核便会开始加载 systemd 并将控制权移交给它。\nStartup 阶段 systemd 是所有进程之父，它负责使计算机达到可以完成生产工作的状态。其功能比过去的 init 程序要丰富得多，包括挂载文件系统、启动和管理计算机所需的系统服务。当然你也可以将一些应用（如 Docker）以 systemd 的方式启动，但它们与 Linux 的启动无关，因此不在本文的讨论范围之内。\n首先，systemd 根据 /etc/fstab 文件中的配置挂载文件系统。然后读取 /etc 目录下的配置文件，包括其自身的配置文件 /etc/systemd/system/default.target。该文件指定了 systemd 需要引导计算机到达的最终目标和状态，实际上是一个软链接：\n1 2  [root@bastion ~]# ls /etc/systemd/system/default.target -l lrwxrwxrwx. 1 root root 37 Oct 17 2019 /etc/systemd/system/default.target -\u003e /lib/systemd/system/multi-user.target   在我使用的 bastion 服务器上，它指向的是 multi-user.target；对于带有图形化界面的桌面工作站，它通常指向 graphics.target；而对于单用户模式的机器，它将指向 emergency.target。target 等效于过去 SystemV 中的 运行级别（Runlevel），它提供了别名以实现向后兼容性：\n   SystemV Runlevel systemd target systemd target alias Description      halt.target  在不关闭电源的情况下中止系统。   0 poweroff.target runlevel0.target 中止系统并关闭电源。   s emergency.target  单用户模式。 没有服务正在运行，也未挂载文件系统。仅在主控制台上运行一个紧急 Shell，供用户与系统交互。   1 rescue.target runlevel1.target 一个基本系统。文件系统已挂载，只运行最基本的服务和主控制台上的紧急 Shell。   2  runlevel2.target 多用户模式。虽然还没有网络连接，但不依赖网络的所有非 GUI 服务都已运行。   3 multi-user.target runlevel3.target 所有服务都在运行，但只能使用命令行界面（CLI）。   4  runlevel4.target 用户自定义   5 graphical.target runlevel5.target 所有服务都在运行，并且可以使用图形化界面（GUI）。   6 reboot.target runlevel6.target 重启系统    每个 target 都在其配置文件中指定了一组依赖，由 systemd 负责启动。这些依赖是 Linux 达到某个运行级别所必须的服务（service）。换句话说，当一个 target 配置文件中的所有 service 都已成功加载，那么系统就达到了该 target 对应的运行级别。\n下图展示了 systemd 启动过程中各 target 和 service 实现的一般顺序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  cryptsetup-pre.target veritysetup-pre.target | (various low-level v API VFS mounts: (various cryptsetup/veritysetup devices...) mqueue, configfs, | | debugfs, ...) v | | cryptsetup.target | | (various swap | | remote-fs-pre.target | devices...) | | | | | | | | | v | v local-fs-pre.target | | | (network file systems) | swap.target | | v v | | | v | remote-cryptsetup.target | | | (various low-level (various mounts and | remote-veritysetup.target | | | services: udevd, fsck services...) | | remote-fs.target | | tmpfiles, random | | | / | | seed, sysctl, ...) v | | / | | | local-fs.target | | / | | | | | | / \\____|______|_______________ ______|___________/ | / \\ / | / v | / sysinit.target | / | | / ______________________/|\\_____________________ | / / | | | \\  | / | | | | | | / v v | v | | / (various (various | (various | |/ timers...) paths...) | sockets...) | | | | | | | | v v | v | | timers.target paths.target | sockets.target | | | | | | v | v \\_______ | _____/ rescue.service | \\|/ | | v v | basic.target rescue.target | | | ________v____________________ | / | \\  | | | | | v v v | display- (various system (various system | manager.service services services) | | required for | | | graphical UIs) v v | | multi-user.target emergency.service | | | | \\_____________ | _____________/ v \\|/ emergency.target v graphical.target   如上图所示，想要到达到某个 target，其依赖的所有 target 和 service 就必须已完成加载。如实现 sysinit.target，需要先挂载文件系统（local-fs.target）、设置交换文件（swap.target）、初始化 udev （various low-level services）和设置加密服务（cryptsetup.target）等。不过，同一个 target 的不同依赖项可以并行执行。\n当计算机达到 multi-user.target 或 graphical.target 时，它的漫漫启动之路就走到了尽头。但为了满足用户多样的需求，它所面临的挑战其实才刚刚开始。\nFuture Work  前言提到 RedHat 官方给出了 IPXE/PXE 引导 CoreOS 系统的方法，那么这项技术又是如何实现的呢？ MBR 只有 446 个字节，可为什么 boot.img 文件却有 512 个字节？ 目前已经有越来越多的计算机使用 UEFI 和 GPT 来代替 BIOS 和 MBR，其优势体现在哪？ 我们该如何理解 systemd 的配置文件？如何使用 systemd 部署我们的应用？  参考文献 Creating Red Hat Enterprise Linux CoreOS (RHCOS) machines by PXE or iPXE Booting\nBIOS - Wikipedia\nINT 13H - Wikipedia\n主引导记录 - Wikipedia\nAn Introduction To the Linux Boot and Startup Processes\nGNU GRUB Manual 2.06\nBootup(7) - Linux manual page\n","description":"","tags":["OS","Linux","CoreOs"],"title":"通过安装 CoreOS 系统了解 Linux 启动流程","uri":"/posts/linux-boot-intro/"},{"categories":null,"content":"前言 在 Kubernetes Pod 是如何跨节点通信的？中，我们简单地介绍了 Kubernetes 中的两种 SDN 网络模型：Underlay 和 Overlay。而 Openshift 中的 SDN 则是由 Overlay 网络 OVS（Open vSwitch）实现的，其使用的插件如下：\n ovs-subnet: 默认插件，提供一个扁平化的 Pod 网络以实现 Pod 与其他任何 Pod 或 Service 的通信； ovs-multitenant：实现多租户管理，隔离不同 Project 之间的网络通信。每个 Project 都有一个 NETID（即 VxLAN 中的 VNID），可以使用 oc get netnamespaces 命令查看； ovs-networkpolicy：基于 Kubernetes 中的 NetworkPolicy 资源实现网络策略管理。  OVS 在每个 Openshift 节点上都创建了如下网络接口：\n br0：OpenShift 创建和管理的 OVS 网桥，它会使用 OpenFlow 流表来实现数据包的转发和隔离； vxlan0：VxLAN 隧道端点，即 VTEP（Virtual Tunnel End Point），用于集群内部 Pod 之间的通信； tun0：节点上所有 Pod 的默认网关，用于 Pod 与集群外部和 Pod 与 Service 之间的通信； veth：Pod 通过veth-pair连接到br0网桥的端点。  使用 ovs-ofctl -O OpenFlow13 show br0 命令可以查看br0上的所有端口及其编号：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  [root@node1 ~]# ovs-ofctl -O OpenFlow13 show br0 OFPT_FEATURES_REPLY (OF1.3) (xid=0x2): dpid:0000ea00372f1940 n_tables:254, n_buffers:0 capabilities: FLOW_STATS TABLE_STATS PORT_STATS GROUP_STATS QUEUE_STATS OFPST_PORT_DESC reply (OF1.3) (xid=0x3): 1(vxlan0): addr:72:23:a0:a9:14:a7 config: 0 state: 0 speed: 0 Mbps now, 0 Mbps max 2(tun0): addr:62:80:67:c6:38:58 config: 0 state: 0 speed: 0 Mbps now, 0 Mbps max 8381(vethd040c191): addr:7a:d9:f4:12:94:5f config: 0 state: 0 current: 10GB-FD COPPER speed: 10000 Mbps now, 0 Mbps max ... LOCAL(br0): addr:76:ab:cf:6f:e1:46 config: PORT_DOWN state: LINK_DOWN speed: 0 Mbps now, 0 Mbps max OFPT_GET_CONFIG_REPLY (OF1.3) (xid=0x5): frags=nx-match miss_send_len=0   考虑到 Openshift 集群的复杂性，我们分别按以下几种场景分析数据包的流向：\n 节点内 Pod 互访：Pod to Local Pod Pod 跨节点互访：Pod to Remote Pod Pod 访问 Service：Pod to Service Pod 与集群外部互访：Pod to External  由于高版本（3.11 以上）的 Openshift 不再以守护进程而是以 Pod 的形式部署 OVS 组件，不方便对 OpenFlow 流表进行查看，因此本文选用的集群版本为 3.6：\n1 2 3 4 5 6 7 8  [root@node1 ~]# oc version  oc v3.6.173.0.5 kubernetes v1.6.1+5115d708d7 features: Basic-Auth GSSAPI Kerberos SPNEGO Server https://test-cluster.ocp.koktlzz.com:8443 openshift v3.6.173.0.5 kubernetes v1.6.1+5115d708d7   另外，实验用集群并未开启 ovs-multitenant，即未进行多租户隔离。整个集群 Pod 网络是扁平化的，所有 Pod 的 VNID 都为默认值 0。\nPod to Local Pod 数据包首先通过veth-pair送往 OVS 网桥br0，随后便进入了br0上的 OpenFlow 流表。我们可以用 ovs-ofctl -O OpenFlow13 dump-flows br0 命令查看流表中的规则，同时为了让输出结果更加简洁，略去 cookie 和 duration 的信息：\n table=0, n_packets=62751550874, n_bytes=25344802160312, priority=200,ip,in_port=1,nw_src=10.128.0.0/14,nw_dst=10.130.8.0/23 actions=move:NXM_NX_TUN_ID[0..31]-\u003eNXM_NX_REG0[],goto_table:10 table=0, n_packets=1081527047094, n_bytes=296066911370148, priority=200,ip,in_port=2 actions=goto_table:30 table=0, n_packets=833353346930, n_bytes=329854403266173, priority=100,ip actions=goto_table:20  table0 中关于 IP 数据包的规则主要有三条，其中前两条分别对应流入端口in_port为 1 号端口vxlan0和 2 号端口tun0的数据包。这两条规则的优先级priority都是 200，因此只有在两者均不符合情况下，才会匹配第三条规则。由于本地 Pod 发出的数据包是由veth端口进入的，因此将转到 table20；\n table=20, n_packets=607178746, n_bytes=218036511085, priority=100,ip,in_port=8422,nw_src=10.130.9.154 actions=load:0-\u003eNXM_NX_REG0[],goto_table:21 table=21, n_packets=833757781068, n_bytes=329871389393381, priority=0 actions=goto_table:30  table20 会匹配源地址nw_src为 10.130.9.154 且流入端口in_port为 8422 的数据包，随后将 Pod1 的 VNID 0 作为源 VNID 存入寄存器 0 中，经由 table21 转到 table30；\n table=30, n_packets=1116329752668, n_bytes=294324730186808, priority=200,ip,nw_dst=10.130.8.0/23 actions=goto_table:70 table=30, n_packets=59672345347, n_bytes=41990349575805, priority=100,ip,nw_dst=10.128.0.0/14 actions=goto_table:90 table=30, n_packets=21061319859, n_bytes=29568807363654, priority=100,ip,nw_dst=172.30.0.0/16 actions=goto_table:60 table=30, n_packets=759636044089, n_bytes=280576476818108, priority=0,ip actions=goto_table:100  table30 中匹配数据包目的地址nw_dst的规则有四条，前三条分别对应本节点内 Pod 的 CIDR 网段 10.130.8.0/23、集群内 Pod 的 CIDR 网段 10.128.0.0/14 和 Service 的 ClusterIP 网段 172.30.0.0/16。第四条优先级最低，用于 Pod 对集群外部的访问。由于数据包的目的地址 10.130.9.158 符合第一条规则，且第一条规则的优先级最高，因此将转到 table70；\n table=70, n_packets=597219981, n_bytes=243824445346, priority=100,ip,nw_dst=10.130.9.158 actions=load:0-\u003eNXM_NX_REG1[],load:0x20ea-\u003eNXM_NX_REG2[],goto_table:80  table70 匹配目的地址nw_dst为 Pod2 IP 10.130.9.158 的数据包，并将 Pod2 的 VNID 0 作为目的 VNID 存入寄存器 1 中。同时端口号0x20ea被保存到寄存器 2 中，然后转到 table80；\n table=80, n_packets=1112713040332, n_bytes=293801616636499, priority=200 actions=output:NXM_NX_REG2[]  table80 比较寄存器 0 和寄存器 1 中保存的源/目的 VNID。若二者一致，则根据寄存器 2 中保存的端口号将数据包送出。\n端口号0x20ea是一个十六进制数字，即十进制数 8426。而 Pod2 正是通过 8426 号端口设备vethba48c6de连接到br0上，因此数据包便最终通过它流入到了 Pod2 中。\n1 2  [root@node1 ~]# ovs-ofctl -O OpenFlow13 show br0 | grep 8426 8426(vethba48c6de): addr:e6:b2:7e:42:41:91   Pod to Remote Pod Packet in Local Pod 数据包依然首先通过veth-pair送往 OVS 网桥br0，随后便进入了br0上的 OpenFlow 流表：\n table=0, n_packets=830232155588, n_bytes=328613498734351, priority=100,ip actions=goto_table:20 table=20, n_packets=1901, n_bytes=299279, priority=100,ip,in_port=6635,nw_src=10.130.9.154 actions=load:0-\u003eNXM_NX_REG0[],goto_table:21 table=21, n_packets=834180030914, n_bytes=330064497351030, priority=0 actions=goto_table:30  与 Pod to Local Pod 的流程一致，数据包根据规则转到 table30；\n table=30, n_packets=59672345347, n_bytes=41990349575805, priority=100,ip,nw_dst=10.128.0.0/14 actions=goto_table:90 table=30, n_packets=1116329752668, n_bytes=294324730186808, priority=200,ip,nw_dst=10.130.8.0/23 actions=goto_table:70  数据包的目的地址为 Pod2 IP 10.131.8.206，不属于本节点 Pod 的 CIDR 网段 10.130.8.0/23，而属于集群 Pod 的 CIDR 网段 10.128.0.0/14，因此转到 table90；\n table=90, n_packets=15802525677, n_bytes=6091612778189, priority=100,ip,nw_dst=10.131.8.0/23 actions=move:NXM_NX_REG0[]-\u003eNXM_NX_TUN_ID[0..31],set_field:10.122.28.8-\u003etun_dst,output:1  table90 根据目的 IP 的所属网段 10.131.8.0/23 判断其位于 Node2 上，于是将 Node2 IP 10.122.28.8 设置为tun_dst。并且从寄存器 0 中取出 VNID 的值，从 1 号端口vxlan0输出。\nvxlan0作为一个 VTEP 设备（参见 Overlay Network），将根据 table90 发来的信息，对数据包进行一层封装：\n 目的地址（dst IP） –\u003e tun_dst –\u003e 10.122.28.8 源地址（src IP） –\u003e Node1 IP –\u003e 10.122.28.7 源 VNID –\u003e NXM_NX_TUN_ID[0..31] –\u003e 0  由于封装后的数据包源/目的地址均为节点 IP，因此从 Node1 的网卡流出后，可以通过物理网络设备转发到 Node2 上。\nPacket in Remote Pod Node2 上的vxlan0对数据包进行解封，随后从br0上的 1 号端口进入 OpenFlow 流表中：\n table=0, n_packets=52141153195, n_bytes=17269645342781, priority=200,ip,in_port=1,nw_src=10.128.0.0/14,nw_dst=10.131.8.0/23 actions=move:NXM_NX_TUN_ID[0..31]-\u003eNXM_NX_REG0[],goto_table:10  table0 判断数据包的流入端口in_port、源 IP 所属网段nw_src和目的 IP 所属网段nw_dst均符合该条规则，于是保存数据包中的源 VNID 到寄存器 0 后转到 table10；\n table=10, n_packets=10147760036, n_bytes=4060517391502, priority=100,tun_src=10.122.28.7 actions=goto_table:30  table10 确认 VxLAN 隧道的源 IPtun_src就是节点 Node1 的 IP 地址，于是转到 table30；\n table=30, n_packets=678759566065, n_bytes=172831151192704, priority=200,ip,nw_dst=10.131.8.0/23 actions=goto_table:70  table30 确认数据包的目的 IP（即 Pod2 IP）存在于 Node2 中 Pod 的 CIDR 网段内，因此转到 table70；\n table=70, n_packets=193211683, n_bytes=27881218388, priority=100,ip,nw_dst=10.131.8.206 actions=load:0-\u003eNXM_NX_REG1[],load:0x220-\u003eNXM_NX_REG2[],goto_table:80  table70 发现数据包的目的 IP 与 Pod2 IP 相符，于是将 Pod2 的 VNID 作为目的 VNID 存于寄存器 1 中，将0x220（十进制数 544）保存在寄存器 2 中，然后转到 table80；\n table=80, n_packets=676813794014, n_bytes=172576112594488, priority=200 actions=output:NXM_NX_REG2[]  table80 会检查保存在寄存器 0 和寄存器 1 中的源/目的 VNID，若相等（此例中均为 0），则从 544 号端口输出。\nbr0上的 544 端口对应的网络接口是vethe9f523a9，因此数据包便最终通过它流入到了 Pod2 中。\n1 2  [root@node2 ~]# ovs-ofctl -O OpenFlow13 show br0 | grep 544 544(vethe9f523a9): addr:b2:a1:61:00:dc:3b   Pod to Service 在本例中，Pod1 通过 Service 访问其后端的 Pod2，其 ClusterIP 为 172.30.107.57，监听的端口为 8080：\n1 2 3  [root@node1 ~]# oc get svc NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE myService 172.30.107.57 \u003cnone\u003e 8080/TCP 2y    table=30, n_packets=21065939280, n_bytes=29573447694924, priority=100,ip,nw_dst=172.30.0.0/16 actions=goto_table:60  数据包在送到 OpenFlow 流表 table30 前的步骤与 Pod to Local Pod 和 Pod to Remote Pod 中的情况一致，但数据包的目的地址变为了 myService 的 ClusterIP。因此将匹配nw_dst中的 172.30.0.0/16 网段，转到 table60；\n table=60, n_packets=0, n_bytes=0, priority=100,tcp,nw_dst=172.30.107.57,tp_dst=8080 actions=load:0-\u003eNXM_NX_REG1[],load:0x2-\u003eNXM_NX_REG2[],goto_table:80  table60 匹配目的地址nw_dst为 172.30.107.57 且目的端口为 8080 的数据包，并将 Pod1 的 VNID 0 保存到寄存器 1 中，将0x2（十进制数字 2）保存到寄存器 2 中，转到 table80；\n table=80, n_packets=1113435014018, n_bytes=294106102133061, priority=200 actions=output:NXM_NX_REG2[]  table80 首先检查目的 Service 的 VNID 是否与寄存器 1 中的 VNID 一致，然后根据寄存器 2 中的数字将数据包从 2 号端口tun0送出，最后进入节点的 iptables 规则中。\niptables 对数据包的处理流程如下图所示：\n由于 Service 的实现依赖于 NAT（上图中的紫色方框），因此我们可以在 NAT 表中查看到与之相关的规则：\n1 2 3 4 5 6 7 8  [root@node1 ~]# iptables -t nat -nvL Chain OUTPUT (policy ACCEPT 4753 packets, 489K bytes) pkts bytes target prot opt in out source destination 2702M 274G KUBE-SERVICES all -- * * 0.0.0.0/0 0.0.0.0/0 /* kubernetes service portals */ Chain KUBE-SERVICES (2 references) pkts bytes target prot opt in out source destination 4 240 KUBE-SVC-QYWOVDCBPMWAGC37 tcp -- * * 0.0.0.0/0 172.30.107.57 /* demo/myService:8080-8080 cluster IP */ tcp dpt:8080   本机产生的数据包（Locally-generated Packet）首先进入OUTPUT链，然后匹配到自定义链KUBE-SERVICES。由于其目的地址为 Service 的 ClusterIP 172.30.107.57，因此将再次跳转到对应的KUBE-SVC-QYWOVDCBPMWAGC37链：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  Chain KUBE-SVC-QYWOVDCBPMWAGC37 (1 references) pkts bytes target prot opt in out source destination 1 60 KUBE-SEP-AF5DIL6JV3XLLV6G all -- * * 0.0.0.0/0 0.0.0.0/0 /* demo/myService:8080-8080 */ statistic mode random probability 0.50000000000 1 60 KUBE-SEP-ADAJHSV7RYS5DUBX all -- * * 0.0.0.0/0 0.0.0.0/0 /* demo/myService:8080-8080 */ Chain KUBE-SEP-ADAJHSV7RYS5DUBX (1 references) pkts bytes target prot opt in out source destination 0 0 KUBE-MARK-MASQ all -- * * 10.131.8.206 0.0.0.0/0 /* demo/myService:8080-8080 */ 0 0 DNAT tcp -- * * 0.0.0.0/0 0.0.0.0/0 /* demo/myService:8080-8080 */ tcp to:10.131.8.206:8080 Chain KUBE-SEP-AF5DIL6JV3XLLV6G (1 references) pkts bytes target prot opt in out source destination 0 0 KUBE-MARK-MASQ all -- * * 10.128.10.57 0.0.0.0/0 /* demo/myService:8080-8080 */ 23 1380 DNAT tcp -- * * 0.0.0.0/0 0.0.0.0/0 /* demo/myService:8080-8080 */ tcp to:10.128.10.57:8080   KUBE-SVC-QYWOVDCBPMWAGC37链下有两条完全相同的匹配规则，对应了该 Service 后端的两个 Pod。KUBE-SEP-ADAJHSV7RYS5DUBX链和 KUBE-SEP-AF5DIL6JV3XLLV6G链能够执行 DNAT 操作，分别将数据包的目的地址转化为 Pod IP 10.131.8.206 和 10.128.10.57。在一次通信中只会有一条链生效，这体现了 Service 的负载均衡能力。\n完成OUTPUTDNAT 的数据包将进入节点的路由判断（Routing Decision）。由于当前目的地址已经属于集群内 Pod 的 CIDR 网段 10.128.0.0/14，因此将再次从tun0端口再次进入 OVS 网桥br0中。\n1 2 3 4 5 6 7 8 9  [rootnode1 ~]# route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 10.122.28.1 0.0.0.0 UG 0 0 0 eth0 10.122.28.0 0.0.0.0 255.255.255.128 U 0 0 0 eth0 10.128.0.0 0.0.0.0 255.252.0.0 U 0 0 0 tun0 169.254.0.0 0.0.0.0 255.255.0.0 U 1008 0 0 eth0 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 172.30.0.0 0.0.0.0 255.255.0.0 U 0 0 0 tun0   不过数据包在进入br0之前，还需要经过 iptables 中的POSTROUTING链，完成一次 MASQUERADE 操作：数据包的源地址转换为其流出端口的 IP，即tun0的 IP 10.130.8.1。\n1 2 3 4 5 6 7 8 9 10 11  [root@node1 ~]# iptables -t nat -nvL  Chain POSTROUTING (policy ACCEPT 5083 packets, 524K bytes) pkts bytes target prot opt in out source destination 2925M 288G OPENSHIFT-MASQUERADE all -- * * 0.0.0.0/0 0.0.0.0/0 /* rules for masquerading OpenShift traffic */ Chain OPENSHIFT-MASQUERADE (1 references) pkts bytes target prot opt in out source destination 321M 19G MASQUERADE all -- * * 10.128.0.0/14 0.0.0.0/0 /* masquerade pod-to-service and pod-to-external traffic */ [root@node1 ~]# ip a | grep tun0 16: tun0: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1450 qdisc noqueue state UNKNOWN qlen 1000 inet 10.130.8.1/23 scope global tun0   本例中 Service 的后端 Pod 均在 Pod1 所在的节点外，因此数据包第二次进入 OpenFlow 流表时匹配的规则基本与 Pod to Remote Pod 一致：\n table=0, n_packets=1081527047094, n_bytes=296066911370148, priority=200,ip,in_port=2 actions=goto_table:30 table=30, n_packets=59672345347, n_bytes=41990349575805, priority=100,ip,nw_dst=10.128.0.0/14 actions=goto_table:90 table=90, n_packets=15802525677, n_bytes=6091612778189, priority=100,ip,nw_dst=10.131.8.0/23 actions=move:NXM_NX_REG0[]-\u003eNXM_NX_TUN_ID[0..31],set_field:10.122.28.8-\u003etun_dst,output:1  其传递流程如下图所示：\nPod2 返回的数据包在到达 Node1 后将被vxlan0解封装，然后根据其目的地址tun0进入 OpenFlow 流表：\n table=0, n_packets=1084362760247, n_bytes=297224518823222, priority=200,ip,in_port=2 actions=goto_table:30 table=30, n_packets=20784385211, n_bytes=4742514750371, priority=300,ip,nw_dst=10.130.8.1 actions=output:2  数据包从 2 号端口tun0流出后进入节点的 iptables 规则，随后将触发 iptables 的 Connection Tracking 操作：根据 /proc/net/nf_conntrack 文件中的记录进行“DeNAT”。返回数据包的源/目的地址从 Pod2 IP 10.131.8.206 和 tun0 IP 10.130.8.1，变回 Service 的 ClusterIP 172.30.107.57 和 Pod1 IP 10.130.9.154。\n1 2  [root@node1 ~]# cat /proc/net/nf_conntrack | grep -E \"src=10.130.9.154.*dst=172.30.107.57.*dport=8080.*src=10.131.8.206\" ipv4 2 tcp 6 431986 ESTABLISHED src=10.130.9.154 dst=172.30.107.57 sport=80 dport=8080 src=10.131.8.206 dst=10.130.8.1 sport=8080 dport=80 [ASSURED] mark=0 secctx=system_u:object_r:unlabeled_t:s0 zone=0 use=2   Pod to External 数据包依然首先通过veth-pair送往 OVS 网桥br0，随后便进入了br0上的 OpenFlow 流表：\n table=0, n_packets=837268653828, n_bytes=331648403594327, priority=100,ip actions=goto_table:20 table=20, n_packets=613807687, n_bytes=220557571042, priority=100,ip,in_port=8422,nw_src=10.130.9.154 actions=load:0-\u003eNXM_NX_REG0[],goto_table:21 table=21, n_packets=837674296060, n_bytes=331665441915651, priority=0 actions=goto_table:30 table=30, n_packets=759636044089, n_bytes=280576476818108, priority=0,ip actions=goto_table:100 table=100, n_packets=761732023982, n_bytes=282091648536325, priority=0 actions=output:2  数据包从tun0端口流出后进入节点的路由表及 iptables 规则：\n1 2 3 4 5 6 7 8  Chain POSTROUTING (policy ACCEPT 2910 packets, 299K bytes) pkts bytes target prot opt in out source destination 0 0 MASQUERADE all -- * !docker0 172.17.0.0/16 0.0.0.0/0 2940M 289G OPENSHIFT-MASQUERADE all -- * * 0.0.0.0/0 0.0.0.0/0 /* rules for masquerading OpenShift traffic */ Chain OPENSHIFT-MASQUERADE (1 references) pkts bytes target prot opt in out source destination 322M 19G MASQUERADE all -- * * 10.128.0.0/14 0.0.0.0/0 /* masquerade pod-to-service and pod-to-external traffic */   访问集群外部显然需要通过节点的默认网关，因此数据包将从节点网卡eth0送出。而在POSTROUTING链中，数据包的源地址由 Pod IP 转换为了eth0的 IP 10.122.28.7。完整流程如下图所示（图中的 Router 指的是路由器而非 Openshift 中的概念）：\nFuture Work  本文并未涉及 External to Pod 的场景，它是如何实现的？我们都知道 Openshift 是通过 Router（HAProxy）来暴露集群内部服务的，那么数据包在传输过程中的 NAT 操作是怎样进行的？ 除了本文提到的几种网络接口外，Openshift 节点上还存在着ovs-system和vxlan_sys_4789。它们的作用是什么？ Openshift 4.X 版本的网络模型与本文实验用的 3.6 版本相比有那些变化？  参考文献 OpenFlow - Wikipedia\nOVS 在云项目中的使用\nOpenShift SDN - OpenShift Container Platform 3.11\n理解 OpenShift（3）：网络之 SDN\n[译] 深入理解 iptables 和 netfilter 架构\nLinux Netfilter: How does connection tracking track connections changed by NAT?\n","description":"","tags":["Openshift","Network","CNI","Open vSwitch"],"title":"对 Openshift SDN 网络模型的一些探索","uri":"/posts/openshift-sdn/"},{"categories":null,"content":"前言 A Guide to the Kubernetes Networking Model 一文生动形象地介绍了 Kubernetes 中的网络模型，然而受篇幅所限，作者并没有对 Pod 跨节点通信时数据包在节点之间传递的细节进行过多讨论。\n我们已经知道，Docker 使用端口映射的方式实现不同主机间容器的通信，Kubernetes 中同样也有 hostPort 的概念。但是当节点和 Pod 的数量上升后，手动管理节点上绑定的端口是十分困难的，这也是NodePort类型的 Service 的缺点之一。而一旦 Pod 不再“借用”节点的 IP 和端口来暴露自身的服务，就不得不面临一个棘手的问题：Pod 的本质是节点中的进程，节点外的物理网络设备（交换机/路由器）并不知晓 Pod 的存在。它们在接收目的地址为 Pod IP 的数据包时，无法完成进一步的传输工作。\n为此我们需要使用一些 CNI（Container Network Interface）插件来完善 Kubernetes 集群的网络模型，这种新型的网络设计理念称为 SDN（Software-defined Networking）。根据 SDN 实现的层级，我们可以将其分为 Underlay Network 和 Overlay Network：\n Overlay 网络允许设备跨越底层物理网络（Underlay Network）进行通信，而底层却并不知晓 Overlay 网络的存在。Underlay 网络是专门用来承载用户 IP 流量的基础架构层，它与 Overlay 网络之间的关系有点类似物理机和虚拟机。Underlay 网络和物理机都是真正存在的实体，它们分别对应着真实存在的网络设备和计算设备，而 Overlay 网络和虚拟机都是依托在下层实体使用软件虚拟出来的层级。\n Underlay Network 利用 Underlay Network 实现 Pod 跨节点通信，既可以只依赖 TCP/IP 模型中的二层协议，也可以使用三层。但无论哪种实现方式，都必须对底层的物理网络有所要求。\n二层 如图所示，Pod 与节点的 IP 地址均处于同一网段。当 Pod1 向另一节点上的 Pod2 发起通信时，数据包首先通过veth-pair和cbr0送往 Node1 的网卡。由于目的地址 10.86.44.4 与 Node1 同网段，因此 Node1 将通过 ARP 广播请求 10.86.44.4 的 MAC 地址。\nCNI 插件不仅为 Pod 分配 IP 地址，它还会将每个 Pod 所在的节点信息下发给 SDN 交换机。这样当 SDN 交换机接收到 ARP 请求时，将会答复 Pod2 所在节点 Node2 的 MAC 地址，数据包也就顺利地送到了 Node2 上。\n阿里云 Terway 模式的 ACK 服务使用的便是这种网络模型，只不过 Pod 间通信使用的 SDN 交换机不再是节点的交换机（下图中的 Node VSwitch），而是单独创建的 Pod VSwitch：\n三层 如图所示，Pod 与节点的 IP 地址不再处于同一网段。当 Pod1 向另一节点上的 Pod2 发起通信时，数据包首先通过veth-pair和cbr0进入宿主机内核的路由表（Routing Table）。CNI 插件在该表中添加了若干条路由规则，如目的地址为 Pod2 IP 的网关为 Node2 的 IP。这样数据包的目的 MAC 地址就变为了 Node2 的 MAC 地址，它将会通过交换机发送到 Node2 上。\n由于这种实现方式基于三层协议，因此不要求两节点处于同一网段。不过需要将目的地址为 Pod2 IP 的网关设置为 SDN 路由器的 IP，且该路由器能够知晓目的 Pod 所在的节点。这样数据包的目的 MAC 地址就会首先变为 SDN 路由器的 MAC 地址，经过路由器后再变为 Node2 的 MAC 地址：\n通过上面的讨论我们发现，想要实现三层的 Underlay 网络，需要在多个节点间下发和同步路由表。于是很容易想到用于交换路由信息的 BGP（Border Gateway Protocol）协议：\n 边界网关协议（英语：Border Gateway Protocol，缩写：BGP）是互联网上一个核心的去中心化自治路由协议。它通过维护 IP 路由表或“前缀”表来实现自治系统（AS）之间的可达性，属于矢量路由协议。BGP 不使用传统的内部网关协议（IGP）的指标，而使用基于路径、网络策略或规则集来决定路由。因此，它更适合被称为矢量性协议，而不是路由协议。\n 对于 Calico 的 BGP 模式来说，我们可以把集群网络模型视为在每个节点上都部署了一台虚拟路由器。路由器可以与其他节点上的路由器通过 BGP 协议互通，它们称为一对 BGP Peers。Calico 的默认部署方式为 Full-mesh，即创建一个完整的内部 BGP 连接网，每个节点上的路由器均互为 BGP Peers。这种方式仅适用于 100 个节点以内的中小型集群，在大型集群中使用的效率低下。而 Route reflectors 模式则将部分节点作为路由反射器，其他节点上的路由器只需与路由反射器互为 BGP Peers。这样便可以大大减少集群中 BGP Peers 的数量，从而提升效率。\nOverlay Network Overlay 网络可以通过多种协议实现，但通常是对 IP 数据包进行一层外部封装（Encapsulation）。这样底层的 Underlay 网络便只会看到外部封装的数据，而无需处理内部的原有数据。Overlay 网络发送数据包的方式取决于其类型和使用的协议，如基于 VxLAN 实现 Overlay 网络，数据包将被外部封装后以 UDP 协议进行发送：\nOverlay 网络的实现并不依赖于底层物理网络设备，因此我们就以一个两节点不处于同一网段且 Pod 与节点亦处于不同网段的例子来说明 Overlay 网络中的数据包传递过程。集群网络使用 VxLAN 技术组建，虚拟网络设备 VTEP（Virtual Tunnel End Point）将会完成数据包的封装和解封操作。\nNode1 上的 VTEP 收到 Pod1 发来的数据包后，首先会在本地的转发表中查找目的 Pod 所在节点的 IP，即 192.168.1.100。随后它将本机 IP 地址 10.86.44.2、Node2 的 IP 地址 192.168.1.100 和 Pod1 的 VNID（VxLAN Network Identifier）封装在原始数据包外，从 Node1 的网络接口 eth0 送出。由于新构建的数据包源/目的地址均为节点的 IP，因此外部的路由器可以将其转发到 Node2 上。Node2 中的 VTEP 在接收到数据包后会首先进行解封，若源 VNID（Pod1 的 VNID）与目的 VNID（Pod2 的 VNID）一致，便会根据原始数据包中的目的地址 172.100.1.2 将其发送到 Pod2 上。此处的 VNID 检查，主要是为了实现集群的网络策略管理和多租户隔离。\n通过对上述几种 SDN 网络模型的讨论，我们发现只有 Overlay 网络需要对数据包进行封装和解封，因此它的性能相比于 Underlay 网络较差。但 Overlay 网络也有以下优点：\n 对底层网络设备的依赖性最小。即使 Pod 所在的节点发生迁移，依然可以通过 Overlay 网络与原集群实现二层网络的互通； VNID 共有 24 位，因此可以构造出约 1600 万个互相隔离的虚拟网络。  Future Work  除了 VxLAN 以外，还有哪些技术可以实现 Overlay 网络？它们是怎样传输数据的呢？ 本文在讨论 Underlay 网络时提到了 Terway 和 Calico，那么有哪些使用 Overlay 网络的 CNI 插件呢？ 更新：我在 对 Openshift SDN 网络模型的一些探索 中介绍了基于 Overlay 网络的 Open vSwitch； 近年来发展迅速的 Cilium 是怎样实现 SDN 网络的？它所依赖的 eBPF 技术又是什么？  参考文献 Software-defined networking - Wikipedia\nAbout Kubernetes Networking\n使用 Terway 网络插件\n边界网关协议 - Wikipedia\nConfigure BGP peering - Calico\n为什么集群需要 Overlay 网络\n","description":"","tags":["Kubernetes","Network","CNI"],"title":"Kubernetes Pod 是如何跨节点通信的？","uri":"/posts/kubernetes-sdn/"}]